{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip file contains training, test and final submission csv files\n",
    "Jupyter notebook contains the code in python \n",
    "change the your_local_path accordingly \n",
    "\n",
    "While running the code, it might take a few mins as it needs to convert the number to words for both train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_local_path = \"C:/Users/sylve/Downloads/Machine learning/Dataset/Project datasets modified/datasemantics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold,cross_val_score,cross_val_predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(your_local_path+\"training_1.csv\")\n",
    "test_df = pd.read_csv(your_local_path+\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>5573 1189 4017 1207 4768 8542 17 1189 5085 5773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>994</td>\n",
       "      <td>0</td>\n",
       "      <td>6315 7507 6700 4742 1944 2692 3647 4413 6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>5015 8067 5335 1615 7957 5773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>2925 7199 1994 4647 7455 5773 4518 2734 2807 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>7136 1207 6781 237 4971 3669 6193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  category                                               text\n",
       "0  959         0    5573 1189 4017 1207 4768 8542 17 1189 5085 5773\n",
       "1  994         0       6315 7507 6700 4742 1944 2692 3647 4413 6700\n",
       "2  995         0                      5015 8067 5335 1615 7957 5773\n",
       "3  996         0  2925 7199 1994 4647 7455 5773 4518 2734 2807 8...\n",
       "4  997         0                  7136 1207 6781 237 4971 3669 6193"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3729</td>\n",
       "      <td>2705 4888 5050 5815 2472 5157 652 2117 2110 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3732</td>\n",
       "      <td>389 4978 315 5178 513 5249 5853 3267 315 3891 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3761</td>\n",
       "      <td>4478 4231 4858 2638 4231 867 371 686 4888 4179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3015 1911 112 3905 825 337 315 1693 4677 825 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5136 3918 5153 2023 3091 4159 315 3711 1409 27...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text\n",
       "0  3729  2705 4888 5050 5815 2472 5157 652 2117 2110 32...\n",
       "1  3732  389 4978 315 5178 513 5249 5853 3267 315 3891 ...\n",
       "2  3761  4478 4231 4858 2638 4231 867 371 686 4888 4179...\n",
       "3     5  3015 1911 112 3905 825 337 315 1693 4677 825 5...\n",
       "4     7  5136 3918 5153 2023 3091 4159 315 3711 1409 27..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           116\n",
       "category     116\n",
       "text         116\n",
       "text_word    116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['category'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Count plot to check the count of category in train dataset\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(train_df.category)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3464 entries, 0 to 3463\n",
      "Data columns (total 3 columns):\n",
      "id          3464 non-null int64\n",
      "category    3464 non-null int64\n",
      "text        3464 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 81.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1360 entries, 0 to 1359\n",
      "Data columns (total 2 columns):\n",
      "id      1360 non-null int64\n",
      "text    1360 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty attritube called 'text_word' for train dataset\n",
    "train_df['text_word']='nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  category                                               text  \\\n",
      "0      959         0    5573 1189 4017 1207 4768 8542 17 1189 5085 5773   \n",
      "1      994         0       6315 7507 6700 4742 1944 2692 3647 4413 6700   \n",
      "2      995         0                      5015 8067 5335 1615 7957 5773   \n",
      "3      996         0  2925 7199 1994 4647 7455 5773 4518 2734 2807 8...   \n",
      "4      997         0                  7136 1207 6781 237 4971 3669 6193   \n",
      "5      998         0  6730 3349 2325 7714 5773 5172 6254 4097 6500 6...   \n",
      "6      999         0                                 714 4164 5672 8124   \n",
      "7     1000         0       7674 4947 7671 4335 1587 6589 3669 6254 6517   \n",
      "8     1001         0  326 4211 8380 7343 6084 779 8542 3485 5141 307...   \n",
      "9     1002         0                        6546 6949 1309 528 784 5773   \n",
      "10    1003         0  7879 3385 230 7350 2963 7473 5773 4456 941 826...   \n",
      "11    1005         0                           3899 7107 6919 4676 7526   \n",
      "12    1006         0                 2875 7182 4580 2266 3342 1189 3078   \n",
      "13    1007         0  7113 6739 8095 5597 6739 5441 6739 5483 6739 6...   \n",
      "14    1008         0  5598 230 853 5335 3601 2134 1041 5094 1499 577...   \n",
      "15    1009         0  8066 4017 6084 2031 2423 4017 1273 2230 2734 3...   \n",
      "16    1010         0                             1325 8406 163 237 8631   \n",
      "17    1011         0  7152 1253 237 8125 8631 6465 907 5107 3439 647...   \n",
      "18    1012         0  676 349 25 4017 3730 5894 2734 572 3078 4456 6...   \n",
      "19    1013         0  4518 2698 2295 1088 2779 4194 237 2176 1444 27...   \n",
      "20    1014         0  7860 4586 7924 7937 791 1543 5143 6655 7526 58...   \n",
      "21    1015         0     2875 3527 44 2154 5551 3468 3287 8542 1095 572   \n",
      "22    1016         0  5092 3225 8486 5658 6625 1784 3078 7152 3743 7...   \n",
      "23    1017         0                  5270 4184 8542 7444 105 6527 3078   \n",
      "24    1018         0  7408 230 1813 4139 3283 2808 224 2698 7807 393...   \n",
      "25    1019         0  3898 2698 1444 3647 7771 4252 6220 7526 7685 5...   \n",
      "26    1021         0  6591 254 2940 2963 4357 1556 4727 5773 6739 49...   \n",
      "27    1022         0  6084 5063 6349 230 4678 1872 4533 3964 2180 48...   \n",
      "28    1023         0            3866 5773 4442 6169 5922 5620 3485 4017   \n",
      "29    1024         0                 7718 2734 6781 1659 4647 4318 5773   \n",
      "...    ...       ...                                                ...   \n",
      "3434  4763         1  1586 4017 5573 3491 8178 4552 1994 4802 4746 6...   \n",
      "3435  4786         1  7685 2230 4332 5922 5108 3257 3057 4017 5326 5...   \n",
      "3436  4788         1  1586 4017 5573 3491 8178 4552 1994 4746 6901 8...   \n",
      "3437  4799         1  4531 7713 8170 6300 429 7599 3078 4980 8183 50...   \n",
      "3438  4802         1  67 3157 339 1112 950 2830 7313 5435 5798 5773 ...   \n",
      "3439  4809         1  2679 6461 3918 8130 103 2853 3078 6359 747 230...   \n",
      "3440  4828         1  552 1788 2416 4032 2354 2269 1043 1509 3474 53...   \n",
      "3441  4829         1  2985 753 8542 7499 755 1698 5795 216 5658 2486...   \n",
      "3442  4834         1  6787 1630 445 2734 4349 5085 8534 6461 5435 80...   \n",
      "3443  4835         1  6787 8543 5773 5782 6449 7370 333 4017 4032 40...   \n",
      "3444  4836         1  6787 2936 2756 7743 3581 3477 3880 2144 7924 4...   \n",
      "3445  4837         1  6787 3138 3718 2709 3078 7033 7337 7676 254 19...   \n",
      "3446  4838         1  6787 6060 154 4017 2679 6461 8130 8462 520 307...   \n",
      "3447  4839         1  6787 4035 4563 1994 154 5373 4956 6035 4393 40...   \n",
      "3448  4840         1  6787 7477 1383 2207 4017 7033 4298 7337 6043 6...   \n",
      "3449  4841         1  6787 1467 5922 1616 3078 6084 2544 3078 683 39...   \n",
      "3450  4842         1  6787 7288 3718 4332 3713 7924 1115 3280 6589 3...   \n",
      "3451  4843         1  6787 6739 4617 753 7505 3713 1509 4801 237 173...   \n",
      "3452  4844         1  6787 7292 4801 7418 4425 4017 6359 747 230 106...   \n",
      "3453  4845         1  6787 3104 753 6461 7110 1053 5380 5773 2354 17...   \n",
      "3454  4846         1  6787 300 1994 6461 7479 8126 230 5146 5777 577...   \n",
      "3455  4847         1  6787 2897 8584 224 5763 6619 5599 5435 6414 56...   \n",
      "3456  4848         1  6787 6642 3281 1849 497 5615 5711 1280 4438 13...   \n",
      "3457  4849         1  6787 5435 367 8444 3580 237 6433 1994 5922 787...   \n",
      "3458  4850         1   6787 3380 4909 5342 1234 5407 3813 3143 757 8614   \n",
      "3459  4851         1  6787 5435 3515 3324 3477 7337 4234 4328 7606 5...   \n",
      "3460  4852         1  6787 5983 5922 1577 5658 3718 1530 4801 5658 7...   \n",
      "3461  4853         1  6787 3359 4108 5007 3477 4909 5342 224 6663 64...   \n",
      "3462  4854         1  6787 3917 4017 5573 5979 4457 4108 1226 4332 1...   \n",
      "3463  4855         1  6787 636 4017 8618 5941 7410 1352 5239 753 646...   \n",
      "\n",
      "                                              text_word  \n",
      "0     five five seven three   one one eight nine   f...  \n",
      "1     six three one five   seven five zero seven   s...  \n",
      "2     five zero one five   eight zero six seven   fi...  \n",
      "3     two nine two five   seven one nine nine   one ...  \n",
      "4     seven one three six   one two zero seven   six...  \n",
      "5     six seven three zero   three three four nine  ...  \n",
      "6     seven one four   four one six four   five six ...  \n",
      "7     seven six seven four   four nine four seven   ...  \n",
      "8     three two six   four two one one   eight three...  \n",
      "9     six five four six   six nine four nine   one t...  \n",
      "10    seven eight seven nine   three three eight fiv...  \n",
      "11    three eight nine nine   seven one zero seven  ...  \n",
      "12    two eight seven five   seven one eight two   f...  \n",
      "13    seven one one three   six seven three nine   e...  \n",
      "14    five five nine eight   two three zero   eight ...  \n",
      "15    eight zero six six   four zero one seven   six...  \n",
      "16    one three two five   eight four zero six   one...  \n",
      "17    seven one five two   one two five three   two ...  \n",
      "18    six seven six   three four nine   two five   f...  \n",
      "19    four five one eight   two six nine eight   two...  \n",
      "20    seven eight six zero   four five eight six   s...  \n",
      "21    two eight seven five   three five two seven   ...  \n",
      "22    five zero nine two   three two two five   eigh...  \n",
      "23    five two seven zero   four one eight four   ei...  \n",
      "24    seven four zero eight   two three zero   one e...  \n",
      "25    three eight nine eight   two six nine eight   ...  \n",
      "26    six five nine one   two five four   two nine f...  \n",
      "27    six zero eight four   five zero six three   si...  \n",
      "28    three eight six six   five seven seven three  ...  \n",
      "29    seven seven one eight   two seven three four  ...  \n",
      "...                                                 ...  \n",
      "3434  one five eight six   four zero one seven   fiv...  \n",
      "3435  seven six eight five   two two three zero   fo...  \n",
      "3436  one five eight six   four zero one seven   fiv...  \n",
      "3437  four five three one   seven seven one three   ...  \n",
      "3438  six seven   three one five seven   three three...  \n",
      "3439  two six seven nine   six four six one   three ...  \n",
      "3440  five five two   one seven eight eight   two fo...  \n",
      "3441  two nine eight five   seven five three   eight...  \n",
      "3442  six seven eight seven   one six three zero   f...  \n",
      "3443  six seven eight seven   eight five four three ...  \n",
      "3444  six seven eight seven   two nine three six   t...  \n",
      "3445  six seven eight seven   three one three eight ...  \n",
      "3446  six seven eight seven   six zero six zero   on...  \n",
      "3447  six seven eight seven   four zero three five  ...  \n",
      "3448  six seven eight seven   seven four seven seven...  \n",
      "3449  six seven eight seven   one four six seven   f...  \n",
      "3450  six seven eight seven   seven two eight eight ...  \n",
      "3451  six seven eight seven   six seven three nine  ...  \n",
      "3452  six seven eight seven   seven two nine two   f...  \n",
      "3453  six seven eight seven   three one zero four   ...  \n",
      "3454  six seven eight seven   three zero zero   one ...  \n",
      "3455  six seven eight seven   two eight nine seven  ...  \n",
      "3456  six seven eight seven   six six four two   thr...  \n",
      "3457  six seven eight seven   five four three five  ...  \n",
      "3458  six seven eight seven   three three eight zero...  \n",
      "3459  six seven eight seven   five four three five  ...  \n",
      "3460  six seven eight seven   five nine eight three ...  \n",
      "3461  six seven eight seven   three three five nine ...  \n",
      "3462  six seven eight seven   three nine one seven  ...  \n",
      "3463  six seven eight seven   six three six   four z...  \n",
      "\n",
      "[3464 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#convert 'text' attribute to text format and store in seperate attritube called 'text_word', so can apply NLP text analysis \n",
    "\n",
    "for key, value in train_df['text'].iteritems(): \n",
    "    train_df.text_word[key]=\" \".join(train_df.text[key])\n",
    "    train_df.text_word[key]=train_df.text_word[key].replace('1','one').replace('2','two').replace('3','three').replace('4','four').replace('5','five').replace('6','six').replace('7','seven').replace('8','eight').replace('9','nine').replace('0','zero') \n",
    "print(train_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sylve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "corpus = []\n",
    "for i in range(0, 3464):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train_df['text_word'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = train_df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of logestic model \n",
    "logmodel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962536023054755\n",
      "[[334   0]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       334\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       347\n",
      "   macro avg       0.48      0.50      0.49       347\n",
      "weighted avg       0.93      0.96      0.94       347\n",
      "\n",
      "\n",
      "***************\n",
      "0.9711815561959655\n",
      "[[337   1]\n",
      " [  9   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       338\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       347\n",
      "   macro avg       0.49      0.50      0.49       347\n",
      "weighted avg       0.95      0.97      0.96       347\n",
      "\n",
      "\n",
      "***************\n",
      "0.962536023054755\n",
      "[[334   2]\n",
      " [ 11   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       336\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       347\n",
      "   macro avg       0.48      0.50      0.49       347\n",
      "weighted avg       0.94      0.96      0.95       347\n",
      "\n",
      "\n",
      "***************\n",
      "0.9711815561959655\n",
      "[[337   0]\n",
      " [ 10   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       337\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       347\n",
      "   macro avg       0.49      0.50      0.49       347\n",
      "weighted avg       0.94      0.97      0.96       347\n",
      "\n",
      "\n",
      "***************\n",
      "0.9566473988439307\n",
      "[[331   0]\n",
      " [ 15   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       331\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       346\n",
      "   macro avg       0.48      0.50      0.49       346\n",
      "weighted avg       0.92      0.96      0.94       346\n",
      "\n",
      "\n",
      "***************\n",
      "0.9566473988439307\n",
      "[[331   0]\n",
      " [ 15   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       331\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       346\n",
      "   macro avg       0.48      0.50      0.49       346\n",
      "weighted avg       0.92      0.96      0.94       346\n",
      "\n",
      "\n",
      "***************\n",
      "0.9653179190751445\n",
      "[[334   1]\n",
      " [ 11   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       335\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       346\n",
      "   macro avg       0.48      0.50      0.49       346\n",
      "weighted avg       0.94      0.97      0.95       346\n",
      "\n",
      "\n",
      "***************\n",
      "0.9710982658959537\n",
      "[[336   1]\n",
      " [  9   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       337\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       346\n",
      "   macro avg       0.49      0.50      0.49       346\n",
      "weighted avg       0.95      0.97      0.96       346\n",
      "\n",
      "\n",
      "***************\n",
      "0.9595375722543352\n",
      "[[331   0]\n",
      " [ 14   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       331\n",
      "           1       1.00      0.07      0.12        15\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       346\n",
      "   macro avg       0.98      0.53      0.55       346\n",
      "weighted avg       0.96      0.96      0.94       346\n",
      "\n",
      "\n",
      "***************\n",
      "0.976878612716763\n",
      "[[338   0]\n",
      " [  8   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       338\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       346\n",
      "   macro avg       0.49      0.50      0.49       346\n",
      "weighted avg       0.95      0.98      0.97       346\n",
      "\n",
      "\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "#Apply Kfolds validation on the train data and\n",
    "#then applying logestic regression\n",
    "#Accuracy score, confusion matrix, classification report\n",
    "\n",
    "kfold=KFold(n_splits=10,  random_state=None, shuffle=True)\n",
    "\n",
    "for train, val_index in kfold.split(X):\n",
    "    #print(\"Train:\", train, \"Validation:\", val_index) \n",
    "    X_train, X_test = X[train], X[val_index] \n",
    "    y_train, y_test = y[train], y[val_index]\n",
    "    logmodel.fit(X_train, y_train)\n",
    "    #predictions\n",
    "    Predictions = logmodel.predict(X_test)\n",
    "    print(accuracy_score(y_test,Predictions))\n",
    "    cm = confusion_matrix(y_test, Predictions)\n",
    "    print(cm)\n",
    "    print(classification_report(y_test,Predictions))\n",
    "    print()\n",
    "    print(\"***************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96623377, 0.96623377, 0.96533795])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logmodel, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_predict(logmodel, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty attritube called 'text_word' for test dataset\n",
    "test_df['text_word']='nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  \\\n",
      "0     3729  2705 4888 5050 5815 2472 5157 652 2117 2110 32...   \n",
      "1     3732  389 4978 315 5178 513 5249 5853 3267 315 3891 ...   \n",
      "2     3761  4478 4231 4858 2638 4231 867 371 686 4888 4179...   \n",
      "3        5  3015 1911 112 3905 825 337 315 1693 4677 825 5...   \n",
      "4        7  5136 3918 5153 2023 3091 4159 315 3711 1409 27...   \n",
      "5      228  1235 3211 5420 4479 2743 3707 4934 2893 5600 4...   \n",
      "6      236  3777 371 5420 4892 2889 2904 1177 3192 3298 17...   \n",
      "7      241  3192 4793 4415 3517 2543 4960 273 4154 2023 36...   \n",
      "8      251  5920 4479 4225 1392 4921 5893 2959 2462 2744 2...   \n",
      "9      260  389 4978 315 4903 513 5249 5853 3267 315 3891 ...   \n",
      "10     265  4435 1911 4964 5318 5333 5507 315 2272 2462 53...   \n",
      "11      19  700 4255 2849 4994 3695 4362 5850 3211 886 117...   \n",
      "12      21        5600 2849 5406 3560 513 4198 5702 3509 2893   \n",
      "13      22  1911 2215 1961 4051 315 1413 652 4030 1640 329...   \n",
      "14      23  4632 1844 2157 124 659 2638 3073 4278 2023 560...   \n",
      "15      24  1379 4269 3425 3918 1836 1147 4269 589 2944 45...   \n",
      "16      25  1594 1177 3637 59 5850 1911 3298 5420 3128 140...   \n",
      "17      26  4414 3846 3369 315 2435 2543 960 1177 3189 531...   \n",
      "18      27                       5324 5853 4490 734 3663 1177   \n",
      "19      28  1291 513 1909 4362 1785 2893 3996 513 1828 265...   \n",
      "20      29  3189 5765 371 2983 2483 4362 3758 4484 4677 59...   \n",
      "21      30  3353 1177 3578 1177 1911 3783 707 2849 4888 43...   \n",
      "22      31  457 2994 3830 3091 3166 2849 3444 4677 2930 51...   \n",
      "23      32  2011 825 3547 750 4336 4030 4162 1257 1353 450...   \n",
      "24     759  5159 3598 512 652 5924 181 1177 4352 2023 5853...   \n",
      "25     772  1386 2937 2808 3517 2318 2543 98 1110 1318 488...   \n",
      "26     774  415 4921 1946 3328 2893 1047 4331 4677 1331 43...   \n",
      "27     776  3576 513 5507 5179 5678 4889 5414 1460 890 135...   \n",
      "28     780  3103 4276 2070 750 3891 4126 4167 5859 4888 28...   \n",
      "29     783  5152 5642 1281 5610 2023 4670 98 1392 5289 315...   \n",
      "...    ...                                                ...   \n",
      "1330  1517  5642 563 3387 1392 4325 4921 2896 5642 2959 31...   \n",
      "1331  1521  3192 3517 2543 4960 273 4154 2023 3662 4030 52...   \n",
      "1332  1528  900 5635 4737 3399 1133 315 2682 1177 5026 202...   \n",
      "1333  1529  5145 4888 4412 5178 5467 1688 3736 1177 5050 4...   \n",
      "1334  1534  691 3923 371 940 143 4464 1612 5875 839 5058 5...   \n",
      "1335  1536  3452 4435 3192 4677 4269 225 3547 1158 4921 44...   \n",
      "1336  1545  4058 1680 750 4030 2543 4291 4378 652 2543 396...   \n",
      "1337  1556  5476 893 5099 4030 5333 547 750 4479 3516 2976...   \n",
      "1338  1570  999 1688 855 5289 1326 3211 4030 5178 5734 315...   \n",
      "1339  1571  4058 5192 3763 1680 4030 5127 2976 2543 3960 4...   \n",
      "1340  1581  439 2788 1703 4080 750 5853 3516 4484 1177 999...   \n",
      "1341  1583  5219 4121 4888 5050 2976 3240 118 5257 4473 36...   \n",
      "1342  1602  2094 5553 4888 1942 513 2247 1347 4758 513 488...   \n",
      "1343  1604  3823 315 5235 1177 5050 1392 1867 1358 4109 17...   \n",
      "1344  1611  2808 3517 2318 2543 2496 98 877 3794 2462 5308...   \n",
      "1345  1619  623 315 5315 98 3656 4291 4888 5051 4863 4362 ...   \n",
      "1346  1626  5145 4888 4412 5178 792 1688 3736 1177 5050 48...   \n",
      "1347  1634  4058 3639 971 513 4273 5853 5523 1726 1177 135...   \n",
      "1348  1644  1497 3751 805 2004 2865 4828 2543 5523 2598 49...   \n",
      "1349   269  5152 141 5097 5788 4774 4888 1958 4058 2148 48...   \n",
      "1350   271  1724 4123 3115 3465 4362 3390 3188 5046 4307 5...   \n",
      "1351   274  5642 563 3387 1392 4325 4921 2896 5642 2959 31...   \n",
      "1352   292  1876 652 4889 3503 98 1392 5289 98 5436 1177 3...   \n",
      "1353   300  2258 3451 3655 4677 513 4578 4484 3249 5853 23...   \n",
      "1354   308  1027 3115 900 5036 4304 2023 5853 92 645 315 2...   \n",
      "1355   311  3163 4030 3892 3405 1470 2893 3163 4372 4151 3...   \n",
      "1356   324  2336 5820 5775 5853 1392 2336 3777 5655 1355 2...   \n",
      "1357   329  123 4888 1158 5566 2025 2703 1241 652 4030 202...   \n",
      "1358   342  5120 3886 5920 5289 750 4304 2283 3747 2118 32...   \n",
      "1359   352  2808 1703 2496 4362 2443 4666 497 4677 2543 56...   \n",
      "\n",
      "                                              text_word  \n",
      "0     two seven zero five   four eight eight eight  ...  \n",
      "1     three eight nine   four nine seven eight   thr...  \n",
      "2     four four seven eight   four two three one   f...  \n",
      "3     three zero one five   one nine one one   one o...  \n",
      "4     five one three six   three nine one eight   fi...  \n",
      "5     one two three five   three two one one   five ...  \n",
      "6     three seven seven seven   three seven one   fi...  \n",
      "7     three one nine two   four seven nine three   f...  \n",
      "8     five nine two zero   four four seven nine   fo...  \n",
      "9     three eight nine   four nine seven eight   thr...  \n",
      "10    four four three five   one nine one one   four...  \n",
      "11    seven zero zero   four two five five   two eig...  \n",
      "12    five six zero zero   two eight four nine   fiv...  \n",
      "13    one nine one one   two two one five   one nine...  \n",
      "14    four six three two   one eight four four   two...  \n",
      "15    one three seven nine   four two six nine   thr...  \n",
      "16    one five nine four   one one seven seven   thr...  \n",
      "17    four four one four   three eight four six   th...  \n",
      "18    five three two four   five eight five three   ...  \n",
      "19    one two nine one   five one three   one nine z...  \n",
      "20    three one eight nine   five seven six five   t...  \n",
      "21    three three five three   one one seven seven  ...  \n",
      "22    four five seven   two nine nine four   three e...  \n",
      "23    two zero one one   eight two five   three five...  \n",
      "24    five one five nine   three five nine eight   f...  \n",
      "25    one three eight six   two nine three seven   t...  \n",
      "26    four one five   four nine two one   one nine f...  \n",
      "27    three five seven six   five one three   five f...  \n",
      "28    three one zero three   four two seven six   tw...  \n",
      "29    five one five two   five six four two   one tw...  \n",
      "...                                                 ...  \n",
      "1330  five six four two   five six three   three thr...  \n",
      "1331  three one nine two   three five one seven   tw...  \n",
      "1332  nine zero zero   five six three five   four se...  \n",
      "1333  five one four five   four eight eight eight   ...  \n",
      "1334  six nine one   three nine two three   three se...  \n",
      "1335  three four five two   four four three five   t...  \n",
      "1336  four zero five eight   one six eight zero   se...  \n",
      "1337  five four seven six   eight nine three   five ...  \n",
      "1338  nine nine nine   one six eight eight   eight f...  \n",
      "1339  four zero five eight   five one nine two   thr...  \n",
      "1340  four three nine   two seven eight eight   one ...  \n",
      "1341  five two one nine   four one two one   four ei...  \n",
      "1342  two zero nine four   five five five three   fo...  \n",
      "1343  three eight two three   three one five   five ...  \n",
      "1344  two eight zero eight   three five one seven   ...  \n",
      "1345  six two three   three one five   five three on...  \n",
      "1346  five one four five   four eight eight eight   ...  \n",
      "1347  four zero five eight   three six three nine   ...  \n",
      "1348  one four nine seven   three seven five one   e...  \n",
      "1349  five one five two   one four one   five zero n...  \n",
      "1350  one seven two four   four one two three   thre...  \n",
      "1351  five six four two   five six three   three thr...  \n",
      "1352  one eight seven six   six five two   four eigh...  \n",
      "1353  two two five eight   three four five one   thr...  \n",
      "1354  one zero two seven   three one one five   nine...  \n",
      "1355  three one six three   four zero three zero   t...  \n",
      "1356  two three three six   five eight two zero   fi...  \n",
      "1357  one two three   four eight eight eight   one o...  \n",
      "1358  five one two zero   three eight eight six   fi...  \n",
      "1359  two eight zero eight   one seven zero three   ...  \n",
      "\n",
      "[1360 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#convert 'text' attribute to text format and store in seperate attritube called 'text_word', so can apply NLP text analysis \n",
    "\n",
    "for key, value in test_df['text'].iteritems(): \n",
    "    test_df.text_word[key]=\" \".join(test_df.text[key])\n",
    "    test_df.text_word[key]=test_df.text_word[key].replace('1','one').replace('2','two').replace('3','three').replace('4','four').replace('5','five').replace('6','six').replace('7','seven').replace('8','eight').replace('9','nine').replace('0','zero') \n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_1 = []\n",
    "for i in range(0, 1360):\n",
    "    review_1 = re.sub('[^a-zA-Z]', ' ', test_df['text_word'][i])\n",
    "    review_1 = review_1.lower()\n",
    "    review_1 = review_1.split()\n",
    "    ps = PorterStemmer()\n",
    "    review_1 = [ps.stem(word) for word in review_1 if not word in set(stopwords.words('english'))]\n",
    "    review_1 = ' '.join(review_1)\n",
    "    corpus_1.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "c_v = CountVectorizer()\n",
    "X_1 = c_v.fit_transform(corpus_1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "Predictions_1 = logmodel.predict(X_1)\n",
    "print(Predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1360,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category']=pd.DataFrame(Predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Count plot to check the count of category in test dataset\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(test_df.category)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_df= test_df.drop(columns=['text','text_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final submission.csv contains only Id and Category\n",
    "test_final_df.to_csv('C:/Users/sylve/Downloads/Machine learning/Dataset/Project datasets modified/datasemantics/submission.csv', header=True, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
